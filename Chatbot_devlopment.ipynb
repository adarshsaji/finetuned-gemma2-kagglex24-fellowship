{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMEl/ihot4frr5Ky3eOrSJS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarshsaji/finetuned-gemma2-kagglex24-fellowship/blob/main/Chatbot_devlopment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLPktgMc4uQh",
        "outputId": "482dcfb5-615c-455f-9dcb-ff44865170cf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: huggingface\n",
            "Successfully installed huggingface-0.0.1\n",
            "Collecting keras_nlp\n",
            "  Downloading keras_nlp-0.17.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting keras-hub==0.17.0 (from keras_nlp)\n",
            "  Downloading keras_hub-0.17.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.17.0->keras_nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.17.0->keras_nlp) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.17.0->keras_nlp) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.17.0->keras_nlp) (2024.9.11)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.17.0->keras_nlp) (13.9.4)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.17.0->keras_nlp) (0.3.4)\n",
            "Collecting tensorflow-text (from keras-hub==0.17.0->keras_nlp)\n",
            "  Downloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub==0.17.0->keras_nlp) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub==0.17.0->keras_nlp) (4.66.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub==0.17.0->keras_nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub==0.17.0->keras_nlp) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub==0.17.0->keras_nlp) (4.12.2)\n",
            "Collecting tensorflow<2.19,>=2.18.0 (from tensorflow-text->keras-hub==0.17.0->keras_nlp)\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.17.0->keras_nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (1.67.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (3.5.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.17.0->keras_nlp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.17.0->keras_nlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.17.0->keras_nlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.17.0->keras_nlp) (2024.8.30)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (0.45.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (0.13.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.17.0->keras_nlp) (3.0.2)\n",
            "Downloading keras_nlp-0.17.0-py3-none-any.whl (2.0 kB)\n",
            "Downloading keras_hub-0.17.0-py3-none-any.whl (644 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.1/644.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, tensorflow, tensorflow-text, keras-hub, keras_nlp\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-hub-0.17.0 keras_nlp-0.17.0 tensorboard-2.18.0 tensorflow-2.18.0 tensorflow-text-2.18.0\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface\n",
        "!pip install keras_nlp\n",
        "!pip install kagglehub\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import kagglehub\n",
        "import keras_nlp\n",
        "import keras_hub"
      ],
      "metadata": {
        "id": "51WS3q5m47-q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")"
      ],
      "metadata": {
        "id": "spbPdUIK5CAl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "causal_lm = keras_nlp.models.CausalLM.from_preset(\"kaggle://adarshsaji/gemma/keras/gemma-startup-engine\")"
      ],
      "metadata": {
        "id": "JCBCzSEaePTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27be3370-9d1e-4bdb-cdf8-8e2bd7e93120"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/adarshsaji/gemma/keras/gemma-startup-engine/3/download/config.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:00<00:00, 946kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/adarshsaji/gemma/keras/gemma-startup-engine/3/download/task.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.91k/2.91k [00:00<00:00, 3.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/adarshsaji/gemma/keras/gemma-startup-engine/3/download/assets/tokenizer/vocabulary.spm...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.04M/4.04M [00:01<00:00, 2.24MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/adarshsaji/gemma/keras/gemma-startup-engine/3/download/model.weights.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.74G/9.74G [10:17<00:00, 16.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"Instruction:\\n{Instruction}\\n\\nResponse:\\n{Response}\""
      ],
      "metadata": {
        "id": "AGd09sHf-V9O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(\n",
        "    Instruction=\"What is the market size and potential for healthcare billing systems, and how can startups capitalize on this opportunity?\",\n",
        "    Response=\"\",\n",
        ")\n",
        "\n",
        "response = causal_lm.generate(prompt, max_length=2048)"
      ],
      "metadata": {
        "id": "o_EZ1bJXXb7M"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1km9Wi-nXjP3",
        "outputId": "3d916857-d8dc-4687-d7d9-53767d65478d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instruction:\n",
            "What is the market size and potential for healthcare billing systems, and how can startups capitalize on this opportunity?\n",
            "\n",
            "Response:\n",
            "The market size for healthcare billing systems is estimated to be $1.5 billion, with a compound annual growth rate of 10%. Startups can capitalize on this opportunity by developing innovative solutions that address the inefficiencies and challenges in healthcare billing, such as the use of AI and machine learning to automate processes and improve accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "T-ntXPsCDcFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "from typing import List, Tuple\n",
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "class ChatInterface:\n",
        "    def __init__(self):\n",
        "        self.model = causal_lm\n",
        "        self.chat_history: List[Tuple[str, str]] = []\n",
        "        self.system_prompt = \"\"\"\n",
        "You are an AI Tech Consultant, skilled in simplifying technical processes for non-technical users. Guide them in turning ideas into products by offering practical, clear advice on:\n",
        "\n",
        "- Feasibility: Help assess idea feasibility, complexity, and time commitment.\n",
        "- Product Development: Outline the step-by-step journey from idea to launch, including prototyping, testing, and iteration.\n",
        "- Tech Basics: Simplify front-end, back-end, full-stack, and data technologies, explaining their roles in simple terms.\n",
        "- Cost Estimation: Set realistic expectations for costs, covering team size, tech stack, time, and hidden factors.\n",
        "- Tech Recommendations: Suggest suitable technologies and best practices for their idea (e.g., frameworks, cloud solutions).\n",
        "- Collaboration: Advise on team roles (e.g., front-end developers, back-end engineers) and effective communication strategies.\n",
        "- Clarity: Avoid jargon; use analogies and simple language to build user confidence.\n",
        "- If a question is asked out of the above said context respond I can't answer this question.\n",
        "\n",
        "Think step by step, use careful reasoning.\n",
        "\n",
        "\"\"\"\n",
        "        self.MAX_HISTORY = 5  # Maximum number of previous exchanges to keep\n",
        "        self.MIN_CHARS = 10  # Minimum characters required for submission\n",
        "\n",
        "    async def process_message(self, message: str) -> str:\n",
        "        # Format messages for the model\n",
        "        formatted_history = self.format_history()\n",
        "        prompt = f\"{self.system_prompt}\\n\\n{formatted_history}Instruction:\\n{message}\\n\\nResponse:\\n\"\n",
        "\n",
        "        # Generate response\n",
        "        response = self.generate_response(prompt)\n",
        "\n",
        "        # Update chat history\n",
        "        self.update_history(message, response)\n",
        "\n",
        "        return response\n",
        "\n",
        "    def format_history(self) -> str:\n",
        "        return \"\".join(f\"Instruction:\\n{human}\\n\\nResponse:\\n{assistant}\\n\\n\"\n",
        "                       for human, assistant in self.chat_history[-self.MAX_HISTORY:])\n",
        "\n",
        "    def generate_response(self, prompt: str) -> str:\n",
        "        template = \"Instruction:\\n{Instruction}\\n\\nResponse:\\n{Response}\"\n",
        "        input_text = template.format(Instruction=prompt, Response=\"\")\n",
        "\n",
        "        outputs = self.model.generate(input_text, max_length=1000, strip_prompt=True)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def update_history(self, message: str, response: str):\n",
        "        self.chat_history.append((message, response))\n",
        "        if len(self.chat_history) > self.MAX_HISTORY:\n",
        "            self.chat_history = self.chat_history[-self.MAX_HISTORY:]\n",
        "\n",
        "    def create_interface(self):\n",
        "        with gr.Blocks(css=\"footer {visibility: hidden}\") as interface:\n",
        "            gr.Markdown(\"<h1 style='text-align: center;'>🤖 Startup Buddy</h1>\")\n",
        "            gr.Markdown(\"<p style='text-align: center;'>I can answer your startup/tech world related questions!</p>\")\n",
        "            chatbot = gr.Chatbot(\n",
        "                height=500,\n",
        "                show_label=False,\n",
        "                container=True,\n",
        "                scale=1,\n",
        "                value=[[None, \"Here's what I can do to help you on your product development journey:\\n\\n\" +\n",
        "                       \"* Answer recent tech/start-up related questions precisely between October 2023 - October 2024. \\n\" +\n",
        "                       \"* Try `What is the current status of Waymo's commercial robotaxi operations in California?` or `What is the market size and potential for healthcare billing systems, and how can startups capitalize on this opportunity?` * \\n\" +\n",
        "                       \"* Understand your market: I can analyze trends, funding patterns, and competitor activity to help you figure out if your product idea has a good chance of success.\\n\" +\n",
        "                       \"* Map out your path: I'll guide you through the entire process, from brainstorming to launch, with clear steps and actionable advice.\\n\" +\n",
        "                       \"* Know your competition: I can identify your potential rivals, highlight their strengths and weaknesses, and suggest ways to make your product stand out.\\n\" +\n",
        "                       \"* Attract investors: I can share insights on recent funding rounds, investor preferences, and valuation trends to help you prepare for fundraising.\\n\" +\n",
        "                       \"* Choose the right tech: I'll recommend technologies and practices that are popular and effective in the startup world.\\n\" +\n",
        "                       \"* Anticipate challenges: I can point out potential roadblocks based on common startup struggles and suggest strategies to overcome them.\\n\" +\n",
        "                       \"* Plan for growth: I can share successful growth tactics used by other startups to help you scale your business.\\n\\n\" +\n",
        "                       \"Essentially, I'm here to make the complex world of product development more understandable and manageable for you.\\n\\n\" +\n",
        "                       \"What's your product idea? Let's explore it together!\"]],\n",
        "                show_copy_button=True,\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    label=\"Type your message here...\",\n",
        "                    placeholder=\"Type your message here...\",\n",
        "                    show_label=False,\n",
        "                    container=True,\n",
        "                )\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\n",
        "                    \"Submit\",\n",
        "                    size=\"lg\",\n",
        "                )\n",
        "                clear = gr.Button(\n",
        "                    \"Clear Chat\",\n",
        "                    size=\"lg\"\n",
        "                )\n",
        "\n",
        "            async def respond(message, chat_history):\n",
        "                if len(message) < self.MIN_CHARS:\n",
        "                    return message, chat_history\n",
        "\n",
        "                # Clear the initial message when the first user message is sent\n",
        "                if len(chat_history) == 1 and chat_history[0][0] is None:\n",
        "                    chat_history = []\n",
        "                bot_message = await self.process_message(message)\n",
        "                chat_history.append((message, bot_message))\n",
        "                return \"\", chat_history\n",
        "\n",
        "            def check_input_length(message):\n",
        "                return gr.update(interactive=len(message) >= self.MIN_CHARS)\n",
        "\n",
        "            msg.submit(\n",
        "                respond,\n",
        "                inputs=[msg, chatbot],\n",
        "                outputs=[msg, chatbot],\n",
        "                api_name=\"submit\"\n",
        "            ).then(\n",
        "                lambda: gr.update(interactive=False),\n",
        "                outputs=submit_btn\n",
        "            )\n",
        "\n",
        "            submit_btn.click(\n",
        "                respond,\n",
        "                inputs=[msg, chatbot],\n",
        "                outputs=[msg, chatbot],\n",
        "                api_name=\"submit_btn\"\n",
        "            ).then(\n",
        "                lambda: gr.update(interactive=False),\n",
        "                outputs=submit_btn\n",
        "            )\n",
        "\n",
        "            msg.change(\n",
        "                check_input_length,\n",
        "                inputs=msg,\n",
        "                outputs=submit_btn\n",
        "            )\n",
        "\n",
        "            clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "\n",
        "        return interface\n",
        "\n",
        "def main():\n",
        "    chat_interface = ChatInterface()\n",
        "    interface = chat_interface.create_interface()\n",
        "    interface.launch(share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "TSoIoGhhjuSf",
        "outputId": "3cd54ca3-7205-4a57-9c48-bf924d0c278f"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:225: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://d7e0dd8cefd9d86f38.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d7e0dd8cefd9d86f38.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d7e0dd8cefd9d86f38.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZnTxUdYi5FvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}